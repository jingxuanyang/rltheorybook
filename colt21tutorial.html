<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-46766886-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-46766886-4');
  </script>


<script type="text/javascript">
  function visibility_on(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'none')
           e.style.display = 'block';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'none')
           e.style.display = 'block';
  }
  function visibility_off(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'block')
           e.style.display = 'none';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'block')
           e.style.display = 'none';
  }
  function toggle_visibility(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
  }
  function toggle_vis(id) {
      var e = document.getElementById(id);
      if (e.style.display == 'none')
          e.style.display = 'inline';
      else
          e.style.display = 'none';
  }
</script>


  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>CS 4789/5789 Intro to RL</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>


<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>COLT 2021 Tutorial: Statistical Foundations of Reinforcement Learning</name>
              </p>
              
              <br>The past decade has seen tremendous interest in sequential decision making under 
              uncertainty, a broad class of problems involving an agent interacting with an unknown 
              environment to accomplish some goal. Reinforcement learning approaches to addressing 
              these problems have led to recent AI breakthroughs in game playing, robotics, and 
              elsewhere. Inspired by these empirical demonstrations, many researchers from the learning
              theory community have turned their attention to reinforcement learning, in an attempt to 
              better understand these problems and develop new algorithmic principles. Their efforts 
              have led to a more-modern statistical foundation for reinforcement learning that places 
              an emphasis on non-asymptotic characterizations via global convergence, sample 
              complexity, and regret analyses. </br>

              <br>This tutorial will provide an overview of this emerging theory with a focus on the 
              most challenging online exploration setting. The tutorial is organized into three sections:
          <ol>
            <li>Part 1 will cover the necessary background and definitions. We focus here on the most basic setting of tabular Markov Decision Processes and consider problems of increasing difficulty: from planning, to optimization with an exploratory distribution, to online exploration. We will present two algorithms: Natural Policy Gradient for the optimization problem and UCB-Value Iteration for exploration, along with their guarantees. </li>
            <li>Part 2 will be organized in smaller discussion groups led by the tutorial presenters and other researchers in the field. We will cover the analyses for NPG and UCB-VI in detail, highlighting key lemmas that are broadly useful in reinforcement learning, as well as technical connections to related fields. </li>
            <li>Part 3 will focus on online exploration beyond the tabular setting, where function approximation is required for generalization. Here we will provide a tour of the zoo of RL models and complexity measures that enable tractable learning, as well as some statistical barriers. We will close with some open problems and future directions. </li>
          </ol>


          <br>The tutorial will be accessible to all COLT attendees. No background knowledge in RL is required, but we do expect tutorial attendees to be comfortable with the standard mathematical tools used in learning theory research, such as concentration inequalities and some linear algebra. </br>
            </td>
          </tr>
        </table>

        

    

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <heading>Staff</heading>
              </p>
              <p>
                <br><strong>Main Presenters</strong>: <a href="https://people.cs.umass.edu/~akshay/">Akshay Krishnamurthy</a> (MSR NYC), <a href="https://wensun.github.io">Wen Sun</a> (Cornell) </br>
                <br><strong>Presenters</strong>: Chris Dann, Fei Feng, Christina Yu, Andrea Zanette, </br>
                <br><strong> Tutorial time: </strong> August 5th 7:15 - 10:15 am (Mountain Time)  </br>
                
                
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <heading>Zoom / Gather Town Information</heading>
              </p>
              <p>
                 TBD
              </p>
            </td>
          </tr>
        </table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
              <heading>Relavent Notes / Papers</heading>
              </p>
                    <p> 
              Book draft "Reinforcement Learning Theory and
          Algorithms", available 
              <a
          href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf">here</a>.</p>
          
                  </td>
                </tr>
              </table>


              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <p align="center">
                      <heading>Schedule (tentative)</heading>
                    </p>
                    
                    <table>
              <tbody>
                        <tr height="50" bgcolor="#F8F8FF">
                          <td></td>
                          <td></td>
                          <td> <strong>Session</strong></td>
                          <td>Reading</td>
                          <td>Slides/Problem Sets </td>
                        </tr>
                
                        <tr height="50">
                          <td>7:15am-8am</td>
                          <td></td>
                          <td> <strong>Fundamentals</strong>: Markov Decision Processes, Natural Policy Gradient, and Upper Confidence Bound Exploration</td>
                          <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf">Ch.1</a> of AJKS,   </td>, 
                          <td><a href="CS6789_data/basics_MDP.pdf">Slides</a>, <a href="CS6789_data/basics_MDP_annotated.pdf">Annotated slides</a>, Video </td>
                        </tr>
      
                        <tr height="50" bgcolor="#F8F8FF">
                            <td>8:15am-9am</td>
                            <td></td>
                            <td> <strong>Recitation / Practice: </strong>Analysis of UCB-VI and NPG</td>
                            <td></td>
                            <td> </td>
                          </tr>
  
                        
                        <tr height="50">
                            <td>9:15am-10:15am</td>
                            <td></td>
                            <td> <strong>Generalization in RL</strong>: Function Approximation, Bellman Rank, Bilinear Class </td>
                            <td></td>, 
                            <td></td>
                        </tr> 
 
      
                
                     </tbody></td></tr>
                    </table>
      
      
      
                  </td>
                </tr>
              </table>
      
      
              
     

        


     


        
        </td>
    </tr>
  </table>
</body>

</html>
